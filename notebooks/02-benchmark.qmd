---
title: "Benchmarking American Put option pricing algorithms"
author: "Nelson Areal"
date: 2025-12-10
format: html
---

Load the libraries and source the functions.

```{r}
library(tidyverse)
library(bench)
library(furrr)
library(Rcpp)
library(JuliaCall)
library(torch)
library(here)

source(here("R", "ap_naive.R"))
source(here("R", "ap_v1.R"))
source(here("R", "ap_v2.R"))
source(here("R", "ap_v3.R"))
Rcpp::sourceCpp(here("R", "ap_v3_rcpp.cpp"))
source(here("R", "ap_v3_rcpp.R"))
source(here("R", "ap_v3_rcpp_par.R"))
source(here("R", "ap_v3_julia.R"))
source(here("R", "ap_v3_torch.R"))
```


## Benchmark single option pricing with different R implementations

```{r}
s <- 40
k <- 40
v <- 0.30
r <- 0.08
tt <- 0.25
d <- 0
nstep <- 1000

bench_result_one_option_r <- bench::mark(
  ap_naive(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  ap_v1(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  ap_v2(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  ap_v3(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  min_iterations = 10L
)

bench_result_one_option_r
```


## Compute option values for all options in the sample

Read the option parameters sample:
```{r}
option_parameters <- readRDS(here("data", "processed", "option_parameters.rds"))
```

Computation time for calculating the option values for all 2500 options in our sample using the naive R implementation:
```{r}
r_naive_time_all_options <- bench::system_time({
  option_values_naive <- option_parameters |>
    mutate(
      option_value = pmap_dbl(
        list(
          S0 = asset_price,
          K = exercise_price,
          r = riskless_rate,
          q = dividend_rate,
          tt = time_to_maturity,
          sigma = volatility,
          steps = nstep
        ),
        ap_naive,
        .progress = TRUE
      )
    )
})

r_naive_time_all_options
```

And using the most efficient R implementation (version 3):
```{r}
r_v3_time_all_options <- bench::system_time({
  option_values_v3 <- option_parameters |>
    mutate(
      option_value = pmap_dbl(
        list(
          S0 = asset_price,
          K = exercise_price,
          r = riskless_rate,
          q = dividend_rate,
          tt = time_to_maturity,
          sigma = volatility,
          steps = nstep
        ),
        ap_v3,
        .progress = TRUE
      )
    )
})

r_v3_time_all_options
```


## Parallel implementation

Let's create new versions of the functions to capture any errors. 

```{r}
ap_naive_safe <- safely(ap_naive)
ap_v1_safe <- safely(ap_v1)
ap_v2_safe <- safely(ap_v2)
ap_v3_safe <- safely(ap_v3)
```

We can easily parellize the results using the `furrr` package:
```{r}
plan(multisession, workers = 10)
r_v3_par_time_all_options <- bench::system_time({
  option_values_v3_par <- option_parameters |>
    mutate(
      option_value = future_pmap(
        list(
          S0 = asset_price,
          K = exercise_price,
          r = riskless_rate,
          q = dividend_rate,
          tt = time_to_maturity,
          sigma = volatility,
          steps = nstep
        ),
        ap_v3_safe,
        .progress = TRUE
      )
    ) |>
    unnest_wider(option_value, names_sep = "_")
})
r_v3_par_time_all_options
plan(sequential)

stopifnot(all(is.na(option_values_v3_par$option_value_error)))
```

We can do the same for version 2 of the algorithm:
```{r}
plan(multisession, workers = 10)
r_v2_par_time_all_options <- bench::system_time({
  option_values_v2_par <- option_parameters |>
    mutate(
      option_value = future_pmap(
        list(
          S0 = asset_price,
          K = exercise_price,
          r = riskless_rate,
          q = dividend_rate,
          tt = time_to_maturity,
          sigma = volatility,
          steps = nstep
        ),
        ap_v2_safe,
        .progress = TRUE
      )
    ) |>
    unnest_wider(option_value, names_sep = "_")
})
r_v2_par_time_all_options
plan(sequential)

stopifnot(all(is.na(option_values_v2_par$option_value_error)))
```

We can do the same for version 1 of the algorithm:
```{r}
plan(multisession, workers = 10)
r_v1_par_time_all_options <- bench::system_time({
  option_values_v1_par <- option_parameters |>
    mutate(
      option_value = future_pmap(
        list(
          S0 = asset_price,
          K = exercise_price,
          r = riskless_rate,
          q = dividend_rate,
          tt = time_to_maturity,
          sigma = volatility,
          steps = nstep
        ),
        ap_v1_safe,
        .progress = TRUE
      )
    ) |>
    unnest_wider(option_value, names_sep = "_")
})
r_v1_par_time_all_options
plan(sequential)

stopifnot(all(is.na(option_values_v1_par$option_value_error)))
```

And finally, we can do the same for the naive implementation of the algorithm:
```{r}
plan(multisession, workers = 10)
r_naive_par_time_all_options <- bench::system_time({
  option_values_naive_par <- option_parameters |>
    mutate(
      option_value = future_pmap(
        list(
          S0 = asset_price,
          K = exercise_price,
          r = riskless_rate,
          q = dividend_rate,
          tt = time_to_maturity,
          sigma = volatility,
          steps = nstep
        ),
        ap_naive_safe,
        .progress = TRUE
      )
    ) |>
    unnest_wider(option_value, names_sep = "_")
})
r_naive_par_time_all_options
plan(sequential)

stopifnot(all(is.na(option_values_naive_par$option_value_error)))
```


The results are identical across all implementations:
```{r}
identical(
  option_values_naive_par,
  option_values_v1_par
)

identical(
  option_values_v1_par,
  option_values_v2_par
)

identical(
  option_values_v2_par,
  option_values_v3_par
)
```


## Using Rcpp

The Rcpp package allows us to write C++ code that can be called from R, providing significant performance improvements for computationally intensive tasks like the binomial tree algorithm.

### Single Option Benchmark

Let's compare the performance of `ap_v3` (pure R) with `ap_v3_rcpp` (C++ core with R wrapper):

```{r}
bench_result_one_option_rcpp <- bench::mark(
  ap_v3(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  ap_v3_rcpp(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  min_iterations = 10L
)

bench_result_one_option_rcpp
```

Verify that both implementations produce identical results:

```{r}
stopifnot(all.equal(
  ap_v3(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  ap_v3_rcpp(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep)
))
```

### Benchmark on full dataset

Now let's test the Rcpp implementation on the full dataset of 2,500 options:

```{r}
rcpp_v3_time_all_options <- bench::system_time({
  option_values_rcpp <- option_parameters |>
    mutate(
      option_value = pmap_dbl(
        list(
          S0 = asset_price,
          K = exercise_price,
          r = riskless_rate,
          q = dividend_rate,
          tt = time_to_maturity,
          sigma = volatility,
          steps = nstep
        ),
        ap_v3_rcpp,
        .progress = TRUE
      )
    )
})

rcpp_v3_time_all_options
```

Verify correctness - all implementations should produce identical results:

```{r}
stopifnot(all.equal(
  option_values_v3$option_value,
  option_values_rcpp$option_value,
  tolerance = 1e-15
))
```


We can also parallelize the Rcpp implementation using the parallel-safe wrapper.
Since the Rcpp function creates an external pointer to another object in C++, we can only use it in R session where it was created. So we need to modify the R wrapper function to create the external pointer inside the function. This is what the `ap_v3_rcpp_par` is doing.


We first create a safe version of the Rcpp function:
```{r}
ap_v3_rcpp_par_safe <- safely(ap_v3_rcpp_par)
```

```{r}
plan(multisession, workers = 8)
rcpp_v3_par_time_all_options <- bench::system_time({
  option_values_rcpp_par <- option_parameters |>
    mutate(
      option_value = future_pmap(
        list(
          S0 = asset_price,
          K = exercise_price,
          r = riskless_rate,
          q = dividend_rate,
          tt = time_to_maturity,
          sigma = volatility,
          steps = nstep
        ),
        ap_v3_rcpp_par_safe,
        .progress = TRUE,
        .options = furrr_options(seed = TRUE)
      )
    ) |>
    unnest_wider(option_value, names_sep = "_")
})
rcpp_v3_par_time_all_options
plan(sequential)

stopifnot(all(is.na(option_values_rcpp_par$option_value_error)))
```

Verify correctness of parallel implementation:
```{r}
stopifnot(all.equal(
  option_values_v3$option_value,
  option_values_rcpp_par$option_value_result,
  tolerance = 1e-15
))
```


## Using Julia

We can use [JuliaCall: an R package for seamless integration between R and Julia](https://joss.theoj.org/papers/10.21105/joss.01284) package to call Julia code from R.

The function `init_julia_ap` from te file `ap_v3_julia.R` initializes the Julia environment and loads the Julia implementation of the American put option pricing algorithm.
```{r}
init_julia_ap()
```

We can now compare the performance of `ap_v3` (pure R) with `ap_v3_julia` (Julia core with R wrapper):

### Single Option Benchmark

```{r}
bench_result_one_option_julia <- bench::mark(
  ap_v3(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  ap_v3_rcpp(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  ap_v3_julia(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  min_iterations = 10L
)

bench_result_one_option_julia
```

Verify that both implementations produce identical results:

```{r}
stopifnot(all.equal(
  ap_v3(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  ap_v3_julia(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep)
))
```


### Benchmark on Full Dataset

Now let's test the Rcpp implementation on the full dataset of 2,500 options:

```{r}
julia_v3_time_all_options <- bench::system_time({
  option_values_julia <- option_parameters |>
    mutate(
      option_value = pmap_dbl(
        list(
          S0 = asset_price,
          K = exercise_price,
          r = riskless_rate,
          q = dividend_rate,
          tt = time_to_maturity,
          sigma = volatility,
          steps = nstep
        ),
        ap_v3_julia,
        .progress = TRUE
      )
    )
})

julia_v3_time_all_options
```

Verify correctness - all implementations should produce identical results:

```{r}
stopifnot(all.equal(
  option_values_v3$option_value,
  option_values_julia$option_value,
  tolerance = 1e-13
))
```

We can also parallelize the Julia implementation using the parallel-safe wrapper.
Since the Julia function creates an external pointer to another object in Julia, we can only use it in R session where it was created. So we need to use the `ap_v3_julia_auto` function initializes Julia if necessary and calls the option valuation function in Julia.

We first create a safe version of this Julia function:
```{r}
ap_v3_julia_auto_safe <- safely(ap_v3_julia_auto)
```

```{r}
plan(multisession, workers = 8)
julia_v3_par_time_all_options <- bench::system_time({
  option_values_julia_par <- option_parameters |>
    mutate(
      option_value = future_pmap(
        list(
          S0 = asset_price,
          K = exercise_price,
          r = riskless_rate,
          q = dividend_rate,
          tt = time_to_maturity,
          sigma = volatility,
          steps = nstep
        ),
        ap_v3_julia_auto_safe,
        .progress = TRUE,
        .options = furrr_options(seed = TRUE)
      )
    ) |>
    unnest_wider(option_value, names_sep = "_")
})
julia_v3_par_time_all_options
plan(sequential)

stopifnot(all(is.na(option_values_julia_par$option_value_error)))
```

Verify correctness of parallel implementation:
```{r}
stopifnot(all.equal(
  option_values_v3$option_value,
  option_values_julia_par$option_value_result,
  tolerance = 1e-13
))
```


### Batch Processing with Julia-side Parallelization

The previous parallel approach has significant overhead because each R worker initializes its own Julia runtime. A much more efficient approach is to send all parameters to Julia at once and use Julia's native multi-threading.

First, let's reinitialize Julia with a specific number of threads (we'll use 10 threads):
```{r}
# Reinitialize Julia with 10 threads
init_julia_ap(num_threads = 10)
```

Now benchmark the batch processing approach:
```{r}
julia_v3_batch_time_all_options <- bench::system_time({
  option_values_julia_batch <- option_parameters |>
    mutate(
      option_value = ap_v3_julia_batch(
        S0 = asset_price,
        K = exercise_price,
        r = riskless_rate,
        q = dividend_rate,
        tt = time_to_maturity,
        sigma = volatility,
        steps = nstep
      )
    )
})

julia_v3_batch_time_all_options
```

Verify correctness:
```{r}
stopifnot(all.equal(
  option_values_v3$option_value,
  option_values_julia_batch$option_value,
  tolerance = 1e-13
))
```

This batch approach should be significantly faster than the R-side parallel approach (`julia_v3_par_time_all_options`) because:
- Single Julia runtime initialization (no overhead per worker)
- One bulk data transfer instead of many small transfers
- Julia's efficient native threading via `Threads.@threads`


## Using torch

The torch package provides GPU acceleration for tensor operations. Our implementation processes multiple options in batches on the GPU, making it highly efficient for large-scale option pricing.

### Single Option Benchmark

First, let's verify that a single option (as a batch of 1) produces the correct result:

```{r}
bench_result_one_option_torch <- bench::mark(
  ap_v3(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  ap_v3_rcpp(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  ap_v3_julia(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  ap_v3_torch(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  min_iterations = 10L,
  check = FALSE
)

bench_result_one_option_torch
```

Verify correctness:

```{r}
stopifnot(all.equal(
  ap_v3(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  ap_v3_torch(S0 = s, K = k, r = r, q = d, tt = tt, sigma = v, steps = nstep),
  tolerance = 1e-4
))
```

Note that on my mac the GPU uses 32-bit floats by default which limits precision, so the results are only equal up to 4 significant digits.


### Benchmark on Full Dataset with Batching

The torch implementation is designed to process multiple options simultaneously on the GPU. We'll group our 2,500 options into batches and process each batch in a single GPU call.

First, let's create a helper function to process batches:

```{r}
process_torch_batches <- function(data, batch_size, nstep) {
  # Add batch ID
  data_with_batches <- data |>
    mutate(batch_id = ceiling(row_number() / batch_size))

  # Process each batch
  results <- data_with_batches |>
    group_by(batch_id) |>
    nest() |>
    mutate(
      option_value = map(data, function(batch_data) {
        ap_v3_torch(
          S0 = batch_data$asset_price,
          K = batch_data$exercise_price,
          r = batch_data$riskless_rate,
          q = batch_data$dividend_rate,
          tt = batch_data$time_to_maturity,
          sigma = batch_data$volatility,
          steps = nstep
        )
      })
    ) |>
    unnest(c(data, option_value))

  return(results)
}
```

Now benchmark with different batch sizes:

```{r}
# Batch size = 100 (25 batches)
torch_v3_time_batch_100 <- bench::system_time({
  option_values_torch_100 <- process_torch_batches(
    option_parameters,
    batch_size = 100,
    nstep = nstep
  )
})
torch_v3_time_batch_100
```

```{r}
# Batch size = 500 (5 batches)
torch_v3_time_batch_500 <- bench::system_time({
  option_values_torch_500 <- process_torch_batches(
    option_parameters,
    batch_size = 500,
    nstep = nstep
  )
})
torch_v3_time_batch_500
```

Verify correctness - all implementations should produce identical results:

```{r}
stopifnot(all.equal(
  option_values_v3_par$option_value_result,
  option_values_torch_100$option_value,
  tolerance = 1e-4
))


stopifnot(all.equal(
  option_values_v3_par$option_value_result,
  option_values_torch_500$option_value,
  tolerance = 1e-4
))
```

They are only equal up to 4 significant digits due to differences in floating point arithmetic on the GPU. On my mac the GPU uses 32-bit floats by default which limits precision.


## Saving all the benchmark times

```{r}
save(
  bench_result_one_option_r,
  r_naive_time_all_options,
  r_v3_time_all_options,
  r_v3_par_time_all_options,
  r_v2_par_time_all_options,
  r_v1_par_time_all_options,
  r_naive_par_time_all_options,
  bench_result_one_option_rcpp,
  rcpp_v3_time_all_options,
  rcpp_v3_par_time_all_options,
  bench_result_one_option_julia,
  julia_v3_time_all_options,
  julia_v3_par_time_all_options,
  julia_v3_batch_time_all_options,
  bench_result_one_option_torch,
  torch_v3_time_batch_100,
  torch_v3_time_batch_500,
  file = here("data", "processed", "benchmark_results.RData")
)
```